#####################################################
#          Explore and visualize metadata           #
# This includes chemical and entomological data,    #
# as well as location and age                       #
# Author: Geoff Zahn                                #
#####################################################
# Packages
library(tidyverse)
library(readxl)
library(skimr)
library(patchwork)
# Custom color palettes
source("./R/palettes.R")
# Load metadata
meta <- read_xlsx("./metadata/metadata.xlsx")
# First look
glimpse(meta)
skim(meta)
# Extra tidying and prep ####
# Fix column classes
meta$Living_Larvae <- as.numeric(meta$Living_Larvae)
meta$Raw_Exit_Holes <- as.numeric(meta$Raw_Exit_Holes)
# Find analytical chemistry columns / rename compounds
chem_cols <- grep(pattern = "CHEM_",names(meta))
names(meta)[chem_cols] <- str_remove(names(meta)[chem_cols],"CHEM_")
chem_cols <- names(meta)[chem_cols]
# Add total chemical (relative area %) and mean
meta$ChemTotal <- rowSums(meta[,chem_cols])
meta$ChemMean <- meta$ChemTotal / length(chem_cols)
# Find entomology columns
names(meta)
ento_cols <- c("Bolt_Surface_Area_cm2","Raw_Exit_Holes_per_cm2","Raw_Exit_Holes","Living_Larvae")
# Rearrange rows by burn date
meta <- arrange(meta,desc(BurnYear))
# convert Sample_ID to factor
meta$Sample_ID <- factor(meta$Sample_ID,levels = meta$Sample_ID)
# Years since burn
meta$YearsSinceBurn <- 2020 - meta$BurnYear
# Export cleaned and prepped metadata ####
write_csv(meta,"./metadata/cleaned_metadata.csv")
# gather long version of meta with "Chem" column
longmeta <- gather(meta,key = Compound,value = Area,chem_cols)
# Plots of chemistry ####
ggplot(meta,aes(x=Sample_ID,y=ChemTotal)) + geom_col()
# chem over time (by compound)
chem_time_plot <- ggplot(longmeta,aes(x=YearsSinceBurn,y=Area,colour=Compound)) +
geom_point(size=4,alpha=.5) + geom_smooth(se=FALSE,method="lm",color="Black",linetype=2) +
facet_wrap(~Compound) +
scale_color_viridis_d() +
labs(x="Years since tree death",y="Relative Area %") +
theme_bw() +
theme(legend.position = "none",
axis.text.x = element_text(angle=60,hjust=1,face="bold"),
strip.text = element_text(size=12,face="bold"),
axis.title = element_text(size=14,face="bold"))
chem_time_plot
ggsave("./output/figs/Fig1_Chem_Area_over_Time.png",dpi=300,width = 12,height = 8)
# chem over time (mean)
chem_total_plot <- ggplot(meta,aes(x=YearsSinceBurn,y=ChemMean)) +
geom_point() +
geom_smooth(se=TRUE,method="lm",color="Black",linetype=2) +
theme_bw() +
labs(x="Years since tree death",y="Total measured chem relative area %")
chem_total_plot
chem_mean_plot <- ggplot(longmeta,aes(x=YearsSinceBurn,y=Area,color=Raw_Exit_Holes)) +
geom_jitter(size=3,alpha=.5,height = 0,width = .2) +
geom_smooth(se=TRUE,method="lm",color="Black",linetype=2) +
labs(x="Years since tree death",y="Relative area %",color="Number of insect\nexit holes",
caption = "Relative area % shown for all chemical compounds") +
theme_bw() +
theme(axis.title = element_text(size=14,face="bold"),
axis.text = element_text(size=12,face="bold"))
chem_mean_plot
ggsave("./output/figs/Fig2_Chem_Totals_over_Time.png",dpi=300,width = 4,height = 4)
# Yield percent over time
yield_time_plot <- ggplot(longmeta,aes(x=YearsSinceBurn,y=Yield_percent,color=Raw_Exit_Holes)) +
geom_point(size=4) + geom_smooth(se=TRUE,method="lm",color="Black",linetype=2) +
theme_bw() +
labs(x="Years since tree death",y="Yield (% w/w)",color= "Number of insect\nexit holes") +
theme(axis.title = element_text(size=14,face="bold"),
axis.text = element_text(size=12,face="bold"))
yield_time_plot
ggsave("./output/figs/Fig3_Yield_over_Time.png",dpi=300,width = 6,height = 6)
names(longmeta)
#insect holes over time
insect1 <- ggplot(meta,aes(x=YearsSinceBurn,y=Raw_Exit_Holes)) + geom_point(size=2) + theme_bw() +
geom_smooth(method = "lm",color="Black",linetype=2) +
labs(x="",y="Insect exit hole count") +
theme(axis.title = element_text(size=14,face="bold"),
axis.text = element_text(size=12,face="bold"))
insect2 <- ggplot(meta,aes(x=YearsSinceBurn,y=Raw_Exit_Holes_per_cm2)) + geom_point(size=2) + theme_bw() +
geom_smooth(method = "lm",color="Black",linetype=2) +
labs(x="Years since tree death",y="Insect exit holes per cm2")  +
theme(axis.title = element_text(size=14,face="bold"),
axis.text = element_text(size=12,face="bold"))
insect1 / insect2
ggsave("./output/figs/Fig4_Insect_bore-holes_over_Time.png",dpi=300,height = 6,width = 6)
knitr::opts_chunk$set(echo = TRUE)
getwd()
# load data
read.csv("./metadata/cleaned_metadata.csv")
# load data
read.csv("../metadata/cleaned_metadata.csv")
# load data
meta <- read.csv("../metadata/cleaned_metadata.csv")
skimr::skim(meta)
library(tidyverse)
library(skimr)
library(plotly)
names(meta)
library(dada2)
packageVersion("dada2")
library(ShortRead)
packageVersion("ShortRead")
library(Biostrings)
packageVersion("Biostrings")
# find files ####
path <- "../RawSeqsProcessing/DM-FAYE-LOG"
# Process ITS2 reads #
starttime <- Sys.time()
library(dada2)
packageVersion("dada2")
library(ShortRead)
packageVersion("ShortRead")
library(Biostrings)
packageVersion("Biostrings")
# find files ####
path <- "../RawSeqsProcessing/DM-FAYE-LOG"
fnFs <- sort(list.files(path, pattern = "R1_001.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern = "R2_001.fastq.gz", full.names = TRUE))
fnFs <- fnFs[grep("ITS2",fnFs)]
fnRs <- fnRs[grep("ITS2",fnRs)]
# Extract sample names, assuming filenames have format:
get.sample.name <- function(fname){strsplit(basename(fname), "_")[[1]][1]}
sample.names <- unname(sapply(fnFs, get.sample.name))
head(sample.names)
# inspect read qualities
# plotQualityProfile(fnFs[1:4])
# plotQualityProfile(cutRs[1:4])
# filter and trim ####
filtFs <- file.path(path,"ITS2_filts",basename(fnFs))
filtRs <- file.path(path,"ITS2_filts",basename(fnRs))
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, maxN = 0, maxEE = c(3, 3),
truncQ = 10, minLen = 50, rm.phix = TRUE, compress = TRUE, multithread = TRUE)
head(out)
# learn errors ####
errF <- learnErrors(filtFs, multithread = TRUE)
errR <- learnErrors(filtRs, multithread = TRUE)
plotErrors(errF, nominalQ = TRUE)
# de-replicate
derepFs <- derepFastq(filtFs, verbose = TRUE)
derepRs <- derepFastq(filtRs, verbose = TRUE)
# Name the derep-class objects by the sample names
names(derepFs) <- sample.names
names(derepRs) <- sample.names
# sample inferrence ####
dadaFs <- dada(derepFs, err = errF, multithread = TRUE)
dadaRs <- dada(derepRs, err = errR, multithread = TRUE)
# save intermediate output
saveRDS(dadaFs,"./output/dadaFs.RDS")
saveRDS(dadaRs,"./output/dadaRs.RDS")
# merge reads ####
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)
# make sequence table ####
seqtab.mergers(makeSequenceTable(mergers))
seqtab <- makeSequenceTable(dadaFs) # FWD seqs only
dim(seqtab)
dim(seqtab.mergers)
# remove chimeras ####
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
seqtab.mergers.nochim <- removeBimeraDenovo(seqtab.mergers, method="consensus", multithread=TRUE, verbose=TRUE)
# inspect dist. of seq lengths ####
plot(table(nchar(getSequences(seqtab.nochim))))
# track reads through pipeline ####
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers,
getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged",
"nonchim")
rownames(track) <- sample.names
head(track)
saveRDS(seqtab.nochim,"./output/seqtab.nochim.RDS")
seqtab.nochim <- readRDS("./output/seqtab.nochim.RDS")
saveRDS(seqtab.mergers.nochim,"./output/seqtab.mergers.nochim.RDS")
seqtab.nochim <- readRDS("./output/seqtab.mergers.nochim.RDS")
# Assign taxonomy ####
# UNITE general FASTA release for eukaryotes 2 - Created: 2020-02-04 - DOI: 10.15156/BIO/786371
unite.ref <- "./taxonomy/UNITE_Euk_2020-02-04_non-dev.fasta.gz"  # CHANGE ME to location on your machine
# test
# testseqs <- getSequences(seqtab.nochim)[1:3]
# testtaxa <- assignTaxonomy(testseqs, unite.ref, multithread = TRUE, tryRC = FALSE, verbose = TRUE)
# make sequence table ####
seqtab.mergers <- makeSequenceTable(mergers)
seqtab <- makeSequenceTable(dadaFs) # FWD seqs only
dim(seqtab)
dim(seqtab.mergers)
# remove chimeras ####
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
seqtab.mergers.nochim <- removeBimeraDenovo(seqtab.mergers, method="consensus", multithread=TRUE, verbose=TRUE)
# inspect dist. of seq lengths ####
plot(table(nchar(getSequences(seqtab.nochim))))
plot(table(nchar(getSequences(seqtab.mergers.nochim))))
# track reads through pipeline ####
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers,
getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged",
"nonchim")
rownames(track) <- sample.names
head(track)
saveRDS(seqtab.nochim,"./output/seqtab.nochim.RDS")
seqtab.nochim <- readRDS("./output/seqtab.nochim.RDS")
saveRDS(seqtab.mergers.nochim,"./output/seqtab.mergers.nochim.RDS")
seqtab.nochim <- readRDS("./output/seqtab.mergers.nochim.RDS")
# UNITE general FASTA release for eukaryotes 2 - Created: 2020-02-04 - DOI: 10.15156/BIO/786371
unite.ref <- "./taxonomy/UNITE_Euk_2020-02-04_non-dev.fasta.gz"  # CHANGE ME to location on your machine
taxa.merged <- assignTaxonomy(seqtab.mergers.nochim, unite.ref, multithread = TRUE, tryRC = FALSE, verbose = TRUE)
saveRDS(taxa.merged,"./output/taxa.merged.RDS")
taxa.FWD <- assignTaxonomy(seqtab.nochim, unite.ref, multithread = TRUE, tryRC = FALSE, verbose = TRUE)
saveRDS(taxa.FWD,"./output/taxa.FWD.RDS")
taxa.print.FWD <- taxa.FWD  # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
taxa.print.FWD <- taxa.FWD  # Removing sequence rownames for display only
rownames(taxa.print.FWD) <- NULL
head(taxa.print.FWD)
endtime <- Sys.time()
difftime(starttime,endttime)
difftime(starttime,endtime)
-difftime(starttime,endtime)
# Load ALL metadata
meta <- read.csv("./metadata/full_metadata.csv")
meta$Sample.Name. # subset to samples present
# Load ALL metadata
meta <- read.csv("./metadata/full_metadata.csv",stringsAsFactors = FALSE)
meta$Sample.Name. # subset to samples present
seqtab
meta$Sample.Name. %in% row.names(seqtab)  # subset to samples present
row.names(seqtab)
which(meta$Sample.Name. %in% row.names(seqtab))  # subset to samples present
meta <- meta[which(meta$Sample.Name. %in% row.names(seqtab)),]  # subset to samples present
library(tidyverse)
library(phyloseq)
# one for merged reads table
phyloseq(sample_data(meta),
otu_table(seqtab.mergers.nochim),
tax_table(taxa.merged))
# one for merged reads table
phyloseq(sample_data(meta),
otu_table(seqtab.mergers.nochim),
tax_table(taxa.merged,taxa_are_rows = TRUE))
?phyloseq
?tax_table()
tax_table(taxa.merged)
row.names(taxa.merged)
# one for merged reads table
phyloseq(sample_data(meta),
otu_table(seqtab.mergers.nochim),
tax_table(taxa.merged),
taxa_are_rows(taxa.merged))
# one for merged reads table
phyloseq(sample_data(meta),
otu_table(seqtab.mergers.nochim),
tax_table(taxa.merged),
taxa_are_rows = TRUE)
# one for merged reads table
phyloseq(sample_data(meta),
otu_table(seqtab.mergers.nochim,taxa_are_rows = FALSE),
tax_table(taxa.merged))
row.names(seqtab.mergers.nochim)
colnames(seqtab.mergers.nochim)
phyloseq(sample_data(meta),
otu_table(seqtab.mergers.nochim,taxa_are_rows = TRUE),
tax_table(taxa.merged))
phyloseq(sample_data(meta),
otu_table(seqtab.mergers.nochim,taxa_are_rows = FALSE),
tax_table(taxa.merged))
row.names(meta)
row.names(meta) <- meta$Sample.Name.
phyloseq(sample_data(meta),
otu_table(seqtab.mergers.nochim,taxa_are_rows = FALSE),
tax_table(taxa.merged))
ps.merged <- phyloseq(sample_data(meta),
otu_table(seqtab.mergers.nochim,taxa_are_rows = FALSE),
tax_table(taxa.merged))
saveRDS(ps.merged,"./output/ITS2_phyloseq_object.RDS")
library(decontam)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("decontam")
library(decontam)
?isContaminant
names(meta)
# remove contaminant seqs
contams <- isContaminant(ps,method = "prevalence",neg = "NegativeControl")
# remove contaminant seqs
contams <- isContaminant(ps.merged,method = "prevalence",neg = "NegativeControl")
contams
contams$contaminant
contams$contaminant == TRUE
which(contams$contaminant == FALSE)
row.names(contams[which(contams$contaminant == FALSE)])
row.names(contams)[which(contams$contaminant == FALSE)]
noncontams <- row.names(contams)[which(contams$contaminant == FALSE)]
subset_taxa(noncontams)
subset_taxa(ps.merged,noncontams)
taxa_names(ps.merged)
ps.merged
subset_taxa(ps.merged,taxa_names(ps.merged) %in% noncontams)
ps.merged.noncontam <- subset_taxa(ps.merged,taxa_names(ps.merged) %in% noncontams)
sample_data(ps.merged.noncontam)
ps.merged.noncontam@sam_data$Project
# save them as RDS ####
saveRDS(ps.merged.noncontam,"./output/ITS2_phyloseq_object_no-contams.RDS")
# subset to LOG samples only
subset_samples(ps.merged.noncontam, Project == "Juniper")
# subset to LOG samples only
ps.juniper <- subset_samples(ps.merged.noncontam, Project == "Juniper")
ps.juniper@sam_data$NegativeControl
ps.juniper@sam_data$Amplicon
ps.juniper@sam_data$Sample.Name.
# subset to LOG samples only
ps.juniper <- subset_samples(ps.merged.noncontam, Project == "Juniper" & NegativeControl == FALSE)
ps.juniper
# save
saveRDS(ps.juniper,"./output/juniper_phyloseq_object_clean.RDS")
tax_table(ps.juniper)[1,]
ps.juniper@tax_table[,1]
unique(ps.juniper@tax_table[,1])
# remove non-fungi
subset_taxa(ps.juniper,Kingdom == "k__Fungi")
k__Fungi
ps.juniper
# remove non-fungi
ps.juniper <- subset_taxa(ps.juniper,Kingdom == "k__Fungi")
# save
saveRDS(ps.juniper,"./output/juniper_phyloseq_object_clean.RDS")
# save
saveRDS(ps.juniper,"./output/juniper_phyloseq_object_clean_ITS2.RDS")
file.remove("./output/juniper_phyloseq_object_clean.RDS")
# Process ITS2 reads #
starttime <- Sys.time()
library(dada2)
packageVersion("dada2")
library(ShortRead)
packageVersion("ShortRead")
library(Biostrings)
packageVersion("Biostrings")
library(tidyverse)
library(phyloseq)
library(decontam)
# find files ####
path <- "../RawSeqsProcessing/DM-FAYE-LOG"
fnFs <- sort(list.files(path, pattern = "R1_001.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern = "R2_001.fastq.gz", full.names = TRUE))
fnRs
fnFs <- fnFs[grep("16S",fnFs)]
fnRs <- fnRs[grep("16S",fnRs)]
fnRs
# Extract sample names, assuming filenames have format:
get.sample.name <- function(fname){strsplit(basename(fname), "_")[[1]][1]}
sample.names <- unname(sapply(fnFs, get.sample.name))
head(sample.names)
# inspect read qualities
plotQualityProfile(fnFs[1:4])
plotQualityProfile(cutRs[1:4])
plotQualityProfile(fnRs[1:4])
# filter and trim ####
filtFs <- file.path(path,"16S_filts",basename(fnFs))
filtRs <- file.path(path,"16S_filts",basename(fnRs))
filtRs
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, maxN = 0, maxEE = c(2, 2),
truncQ = 15, minLen = 100, rm.phix = TRUE, compress = TRUE, multithread = TRUE)
head(out)
out
list.files("path")
list.files(path)
file.path(path,"16S_filts")
list.files(file.path(path,"16S_filts"))
# reassign filts for lost samples, if any
filtFs <- list.files(file.path(path,"16S_filts"), pattern = "R1_001.fastq.gz", full.names = TRUE)
filtFs
filtRs <- list.files(file.path(path,"16S_filts"), pattern = "R2_001.fastq.gz", full.names = TRUE)
errF <- learnErrors(filtFs, multithread = TRUE)
errR <- learnErrors(filtRs, multithread = TRUE)
plotErrors(errF, nominalQ = TRUE)
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, maxN = 0, maxEE = c(2, 2),
truncQ = 2, minLen = 100, rm.phix = TRUE, compress = TRUE, multithread = TRUE)
head(out)
# reassign filts for lost samples, if any
filtFs <- list.files(file.path(path,"16S_filts"), pattern = "R1_001.fastq.gz", full.names = TRUE)
filtRs <- list.files(file.path(path,"16S_filts"), pattern = "R2_001.fastq.gz", full.names = TRUE)
# learn errors ####
errF <- learnErrors(filtFs, multithread = TRUE)
errR <- learnErrors(filtRs, multithread = TRUE)
plotErrors(errF, nominalQ = TRUE)
# Process ITS2 reads #
starttime <- Sys.time()
library(dada2)
packageVersion("dada2")
library(ShortRead)
packageVersion("ShortRead")
library(Biostrings)
packageVersion("Biostrings")
library(tidyverse)
library(phyloseq)
library(decontam)
# find files ####
path <- "../RawSeqsProcessing/DM-FAYE-LOG"
fnFs <- sort(list.files(path, pattern = "R1_001.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern = "R2_001.fastq.gz", full.names = TRUE))
fnFs <- fnFs[grep("16S",fnFs)]
fnRs <- fnRs[grep("16S",fnRs)]
# Extract sample names, assuming filenames have format:
get.sample.name <- function(fname){strsplit(basename(fname), "_")[[1]][1]}
sample.names <- unname(sapply(fnFs, get.sample.name))
head(sample.names)
# inspect read qualities
plotQualityProfile(fnFs[1:4])
plotQualityProfile(fnRs[1:4])
# filter and trim ####
filtFs <- file.path(path,"16S_filts",basename(fnFs))
filtRs <- file.path(path,"16S_filts",basename(fnRs))
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, maxN = 0, maxEE = c(2, 2),
truncQ = 2, minLen = 100, rm.phix = TRUE, compress = TRUE, multithread = TRUE)
head(out)
# reassign filts for lost samples, if any
filtFs <- list.files(file.path(path,"16S_filts"), pattern = "R1_001.fastq.gz", full.names = TRUE)
filtRs <- list.files(file.path(path,"16S_filts"), pattern = "R2_001.fastq.gz", full.names = TRUE)
# learn errors ####
errF <- learnErrors(filtFs, multithread = TRUE)
errR <- learnErrors(filtRs, multithread = TRUE)
plotErrors(errF, nominalQ = TRUE)
# de-replicate
derepFs <- derepFastq(filtFs, verbose = TRUE)
derepRs <- derepFastq(filtRs, verbose = TRUE)
# Name the derep-class objects by the sample names
names(derepFs) <- sample.names
names(derepRs) <- sample.names
# sample inferrence ####
dadaFs <- dada(derepFs, err = errF, multithread = TRUE)
dadaRs <- dada(derepRs, err = errR, multithread = TRUE)
# save intermediate output
saveRDS(dadaFs,"./output/dadaFs_16S.RDS")
saveRDS(dadaRs,"./output/dadaRs_16S.RDS")
plotErrors(errF, nominalQ = TRUE)
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)
# make sequence table ####
seqtab.mergers <- makeSequenceTable(mergers)
seqtab <- makeSequenceTable(dadaFs) # FWD seqs only
dim(seqtab)
dim(seqtab.mergers)
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
seqtab.mergers.nochim <- removeBimeraDenovo(seqtab.mergers, method="consensus", multithread=TRUE, verbose=TRUE)
# inspect dist. of seq lengths ####
plot(table(nchar(getSequences(seqtab.nochim))))
plot(table(nchar(getSequences(seqtab.mergers.nochim))))
# track reads through pipeline ####
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers,
getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged",
"nonchim")
rownames(track) <- sample.names
head(track)
write.csv(track,"./output/tracked_reads_16S.csv",row.names = FALSE,quote = FALSE)
saveRDS(seqtab.nochim,"./output/seqtab.nochim.RDS")
seqtab.nochim <- readRDS("./output/seqtab.nochim.RDS")
saveRDS(seqtab.mergers.nochim,"./output/seqtab.mergers.nochim.RDS")
seqtab.nochim <- readRDS("./output/seqtab.mergers.nochim.RDS")
taxa <- assignTaxonomy(seqtab.mergers.nochim, "./taxonomy/rdp_train_set_16.fa.gz", multithread=TRUE)
taxa <- addSpecies(taxa, "./taxonomy/rdp_species_assignment_16.fa.gz")
saveRDS(taxa,"./output/taxa.merged.RDS")
taxa.print.FWD <- taxa.FWD  # Removing sequence rownames for display only
rownames(taxa.print.FWD) <- NULL
taxa.print <- taxa  # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
endtime <- Sys.time()
-difftime(starttime,endtime)
# Load ALL metadata
meta <- read.csv("./metadata/full_metadata.csv",stringsAsFactors = FALSE)
meta <- meta[which(meta$Sample.Name. %in% row.names(seqtab)),]  # subset to samples present
colnames(seqtab.mergers.nochim)
row.names(meta) <- meta$Sample.Name.
ps.merged <- phyloseq(sample_data(meta),
otu_table(seqtab.mergers.nochim,taxa_are_rows = FALSE),
tax_table(taxa.merged))
ps.merged <- phyloseq(sample_data(meta),
otu_table(seqtab.mergers.nochim,taxa_are_rows = FALSE),
tax_table(taxa))
# ID and remove contaminant seqs ####
contams <- isContaminant(ps.merged,method = "prevalence",neg = "NegativeControl")
noncontams <- row.names(contams)[which(contams$contaminant == FALSE)]
ps.merged
ps.merged.noncontam
ps.merged.noncontam <- subset_taxa(ps.merged,taxa_names(ps.merged) %in% noncontams)
ps.merged.noncontam
# save them as RDS ####
saveRDS(ps.merged.noncontam,"./output/16S_phyloseq_object_no-contams.RDS")
# subset to LOG samples only
ps.juniper <- subset_samples(ps.merged.noncontam, Project == "Juniper" & NegativeControl == FALSE)
ps.juniper
ps.juniper@tax_table[,1]
ps.juniper@tax_table[1,]
ps.juniper@tax_table[,]
ps.juniper@tax_table[1:10,1:10]
ps.juniper@tax_table[1:10,]
subset_taxa(ps.juniper,Kingdom == "Bacteria")
# remove non-fungi
ps.juniper <- subset_taxa(ps.juniper,Kingdom == "Bacteria")
# save
saveRDS(ps.juniper,"./output/juniper_phyloseq_object_clean_16S.RDS")
